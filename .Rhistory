import random
def flip_coin(n: int = 1) -> list[int]:
"""Return a list of 0 / 1 draws; 1 = heads, 0 = tails."""
return random.choices([0, 1], k=n)
def simulate_50() -> int:
"""Flip a coin 50 × and return the number of heads."""
return sum(flip_coin(50))
random.seed(42)          # reproducible example
simulate_50()
import numpy as np
import matplotlib.pyplot as plt
random.seed(42)
n_sims  = 1000
results = [simulate_50() for _ in range(n_sims)]
# summary statistics
print(f"min  : {min(results)}")
print(f"max  : {max(results)}")
print(f"mean : {np.mean(results):.2f}")
print(f"sd   : {np.std(results, ddof=1):.2f}")
# visualise
plt.hist(results, bins=20, edgecolor="black")
plt.title("Heads in 1 000 × 50-flip experiments")
plt.xlabel("Number of heads")
plt.ylabel("Frequency")
plt.show()
import subprocess, sys, importlib
def ensure(pkg):
try:
importlib.import_module(pkg)
except ImportError:
subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])
for p in ("pandas", "statsmodels", "matplotlib", "xlrd"):
ensure(p)
import pandas as pd
# --- OPTION A: read directly from disk -------------------------------
# df = pd.read_excel("Steroids PNa MA.xls", sheet_name="Sheet1")
# --- OPTION B: reuse the R object saved as CSV / feather -------------
# df = pd.read_feather("steroids_pna.feather")  # if you exported from R
# For this demo we fetch the raw file from GitHub (same content as R block)
url = ("https://raw.githubusercontent.com/reblocke/statistics_sandbox/"
"1b87fb4e65da11a7f9541ea9c7f93b7e3947a13a/"
"Steroids%20PNa/Steroids%20PNa%20MA.xls")
df = pd.read_excel(url)           # GitHub serves raw file
# clean column names to snake_case like janitor::clean_names()
df.columns = (df.columns
.str.strip()
.str.lower()
.str.replace(" ", "_"))
# quick sanity check
df.head(18)
import numpy as np
from statsmodels.stats.meta_analysis import (
effectsize_2proportions,    # log-odds-ratio + variance
combine_effects             # pooling with DL
)
# --- 2. per-study log(OR) & variance with 0.5 correction --------------------
a = df["int_death"].to_numpy(dtype=float)
b = df["int_alive"].to_numpy(dtype=float)
c = df["pla_death"].to_numpy(dtype=float)
d = df["pla_alive"].to_numpy(dtype=float)
# continuity correction if any cell is zero in that study
cc = ((a == 0) | (b == 0) | (c == 0) | (d == 0)).astype(float) * 0.5
a += cc; b += cc; c += cc; d += cc
log_or = np.log((a * d) / (b * c))
var_or = 1 / a + 1 / b + 1 / c + 1 / d          # variance of log(OR)
# --- 3. DerSimonian-Laird random-effects pooling ---------------------------
res = combine_effects(log_or, var_or, method_re="dl")   # DL estimator
print("Current statsmodels version:", importlib.metadata.version("statsmodels"))
sf = res.summary_frame()          # still log-OR
sf["eff"]    = np.exp(sf["eff"])
sf["ci_low"] = np.exp(sf["ci_low"])
sf["ci_upp"] = np.exp(sf["ci_upp"])
print(sf.round(3))
import matplotlib.pyplot as plt
labels = df["study"] + " " + df["year"].astype(str)
fig = res.plot_forest(
line_order = labels,             # ← first positional arg is the label set
use_exp    = True,
xlabel     = "Odds Ratio (death)",
xlim       = (0.03125, 32),
xticks     = [1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32],
color      = "navy"
)
plt.title("Steroids OR for Death, Random-Effects Meta-analysis (DL)")
plt.gca().set_xscale("log")
plt.tight_layout()
plt.show()
import matplotlib.pyplot as plt
fig = res.plot_forest(
use_exp = True,
xlabel  = "Odds Ratio (death)",
xlim    = (0.03125, 32),
xticks  = [1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32],
color   = "navy"
)
plt.title("Steroids OR for Death, Random-Effects Meta-analysis (DL)")
plt.gca().set_xscale("log")
plt.tight_layout()
plt.show()
import matplotlib.pyplot as plt
# draw the default forest plot (no extra kwargs)
fig = res.plot_forest(use_exp=True)
# post-process the axis with Matplotlib
ax = fig.axes[0]          # the single Axes returned by plot_forest
ax.set_xscale("log")
ax.set_xlim(0.03125, 32)
ax.set_xlabel("Odds Ratio (death)")
ax.set_xticks([1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32])
ax.set_xticklabels(
["1/32", "1/16", "1/8", "1/4", "1/2",
"1", "2", "4", "8", "16", "32"]
)
plt.title("Steroids OR for Death, Random-Effects Meta-analysis (DL)")
plt.tight_layout()
plt.show()
source("R/booktem_setup.R")
source("R/my_setup.R")
library(reticulate)
ENV <- "r-reticulate"                         # change if py_config() says otherwise
# point reticulate at the env *before* Python spins up
use_condaenv(ENV, required = TRUE)
if (!py_module_available("matplotlib")) {
message("Installing matplotlib (and numpy) into '", ENV, "' …")
conda_install(envname = ENV,
packages = c("matplotlib", "numpy"),
pip      = FALSE)
message("Restarting embedded Python …")
py_restart_session()                        # <- works in v1.42+
}
## one fair-coin flip: 1 = Heads, 0 = Tails
flip_coin <- function(n = 1) {
sample(c(0, 1), size = n, replace = TRUE)
}
## run one experiment of 50 flips and return #Heads
simulate_50 <- function() {
sum(flip_coin(50))
}
## quick demo
set.seed(42)   # reproducible example
simulate_50()
set.seed(42)                       # reproducible simulations
n_sims  <- 1000                    # how many experiments?
results <- replicate(n_sims, simulate_50())
summary(results)                   # five-number summary
hist(results,
breaks = 20,
main   = "Distribution of heads in 1 000 × 50-flip experiments",
xlab   = "Number of heads")
reticulate::repl_python()
# ---- setup: read Steroids PNa meta-analysis data ---------------------------
library(readxl)      # tidy way to read .xls/.xlsx
library(knitr)       # for kable() later
url  <- "https://raw.githubusercontent.com/reblocke/statistics_sandbox/1b87fb4e65da11a7f9541ea9c7f93b7e3947a13a/Steroids%20PNa/Steroids%20PNa%20MA.xls"
tmpfile <- tempfile(fileext = ".xls")   # Quarto render is read-only; use temp
download.file(url, tmpfile, mode = "wb")
steroids_pna <- read_xls(tmpfile, sheet = 1)
# ---- display the table ------------------------------------------------------
kable(steroids_pna, caption = "Steroids PNa meta-analysis data")
library(readxl)                           # install.packages("readxl") if needed
## --- OPTION A – read from a local copy ------------------------------------
# setwd("~/your_dir")                       # uncomment and edit this line
# dat <- read_xls("Steroids PNa MA.xls", sheet = "Sheet1") |>
#        janitor::clean_names()
## --- OPTION B – read directly from the GitHub raw file             ----
url  <- "https://raw.githubusercontent.com/reblocke/statistics_sandbox/" |>
paste0("1b87fb4e65da11a7f9541ea9c7f93b7e3947a13a/",
"Steroids%20PNa/Steroids%20PNa%20MA.xls")
tmp  <- tempfile(fileext = ".xls")          # download to a temp file
download.file(url, tmp, mode = "wb")
dat  <- read_xls(tmp, sheet = "Sheet1") |>
janitor::clean_names()                       # lower-case, snake_case
# Inspect the key columns
dat |>
dplyr::select(study, year,
int_death, int_alive,
pla_death, pla_alive) |>
print()
library(meta)                             # install.packages("meta")
m <- metabin(
event.e     = int_death,
n.e         = int_death + int_alive,
event.c     = pla_death,
n.c         = pla_death + pla_alive,
studlab     = paste(study, year),
data        = dat,
sm          = "OR",      # odds ratio
method.tau  = "DL",      # <-- DerSimonian–Laird estimator
method.random.ci        = FALSE
)
forest(
m,
comb.fixed  = FALSE,
comb.random = TRUE,
print.tau2  = FALSE,
backtransf  = TRUE,
xlab        = "Odds Ratio (death)",
leftlabs    = c("Study (year)", "Steroid", "Placebo"),
xlog        = TRUE,
at          = c(1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32),
label.e     = "Steroid",
label.c     = "Placebo",
col.diamond = "navy",
overall.lty = 2,
## keep the default right-hand columns
# rightcols = FALSE,          # <-- delete this line
main        = "Steroids OR for Death, Random-Effects Meta-analysis"
)
reticulate::repl_python()
# find citation on how frequently errors occur in scientific programming.
# find citation for data cleaning influence on stability of findings
