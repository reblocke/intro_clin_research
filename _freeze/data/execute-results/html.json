{
  "hash": "7c8cae7ef09ec4cf51ce2aa39613166d",
  "result": {
    "engine": "knitr",
    "markdown": "# Data {#sec-data}\n\n\n\n::: callout-important\n**This section is still under construction**\n:::\n\nYes - this really is that important to deserve its own chapter.\n\n## Getting Data {#sec-get_data}\n\nwhat are some relevant (to PCCM) data-sets.\n\nDatabases compiled by NLM <https://www.datasetcatalog.nlm.nih.gov/index.html> \n\nThe NHLBI Pooled Cohorts Study harmonized spirometry data from nine U.S. population-based cohorts: 9 Prospective US Cohorts from NHLBI  includig spirometry:  (from Am J Epidemiol. 2018;187(11):2265–2278 )\n\nhttps://academic-oup-com.ezproxy.lib.utah.edu/aje/article/187/11/2265/5047150\n\nARIC, Atherosclerosis Risk in Communities\n\nCARDIA, Coronary Artery Risk Development in Young Adults\n\nCHS, Cardiovascular Health Study; \n\nFHS-O, Framingham Heart Study—Offspring Cohort\n\nHABC, Health, Aging and Body Composition\n\nHCHS/SOL, Hispanic Community Health Study/Study of Latinos\n\nJHS, Jackson Heart Study\n\nMESA, Multi-Ethnic Study of Atherosclerosis; \n\nSHS, Strong Heart Study.\n\nSpiromics\n\nCOPDGene\n\nTriNetX\n\nPinc AI Healthcare\n\nSleep: [Sleepdata.org](http://Sleepdata.org)\n\nNCHS: National Center for Health Statistics Datasets:: https://www.cdc.gov/nchs/nhis/nhis_questionnaires.htm\n\nhttps://nhis.ipums.org/nhis/aboutIPUMSNHIS.shtml   \\<— documentation for the NCHS datasets, and an integration of several years with weightings. \n\nReference for sampling designs - <https://stats.oarc.ucla.edu/other/mult-pkg/faq/faq-choosing-the-correct-analysis-for-various-survey-designs/>  ; <https://stats.oarc.ucla.edu/stata/seminars/survey-data-analysis-in-stata-17/> \n\n\\\n\nNHIS—list of variables pertinent to respiratory health: <https://nhis.ipums.org/nhis/userNotes_HP2020.shtml#group14> \n\n— can be linked with the National Death Index\n\nNational Inpatient Sample Data elements: https://hcup-us.ahrq.gov/db/nation/nis/nisdde.jsp\n\nNHANES\n\nMIMIC - III/IV \n\nEICU - <https://www.nature.com/articles/sdata2018178> \n\nSicDB - <https://link.springer.com/article/10.1007/s00134-023-07046-3> Salzburg “SICdb (1.0.4) contains 27,386 admissions from 4 different intensive care units (ICUs) at 1 single tertiary care institution of the Department of Anesthesiology and Intensive Care Medicine at the Salzburger Landesklinik (SALK) and Paracelsus Medical University (PMU) between 2013 and 2021.” 1-per-minute. <https://www.sicdb.com/> \n\n—-\\> comment on anonymization https://link.springer.com/article/10.1007/s00134-023-07153-1 \n\n| **Database** | **Features** | **Link** |\n|----|----|----|\n| MIMIC III | EHR, notes, high-frequency physiology; ICU | <https://physionet.org/content/mimiciii/1.4/> |\n| MIMIC IV | EHR, notes, high-frequency physiology, electrocardiograms, radiologic images, EEG, echocardiograms; Emergency department, hospital, ICU | <https://physionet.org/content/mimiciv/2.2/> |\n| eICU | EHR; ICU | <https://physionet.org/content/eicu-crd/2.0/> |\n| AmsterdamUMCdb | EHR; ICU | <https://amsterdammedicaldatascience.nl/amsterdamumcdb/> |\n| HiRID | EHR, high-frequency physiology; ICU; COVID-19 focused | <https://physionet.org/content/hirid/1.1.1/> |\n| SICdb | EHR; high-frequency physiology; ICU | <https://physionet.org/content/sicdb/1.06/> |\n| Zhejiang | EHR; ICU | <https://physionet.org/content/zhejiang-ehr-critical-care/1.0/> |\n| Pediatric Intensive Care | EHR; ICU | <https://physionet.org/content/picdb/1.1.0/> |\n\nUPDB \\*\\*\\*\n\nNHLBI BioData Catalyst - <https://academic-oup-com.ezproxy.lib.utah.edu/jamia/article/30/7/1293/7165700?utm_source=etoc&utm_campaign=jamia&utm_medium=email&nbd=41184264570&nbd_source=campaigner> - includes TOPmed, COVID data-sets. Idea = a place for researchers to store these resources\n\nEDW. \n\nResearch Networks: (get Limited dataset) \n\n-PCORNET (can access broad network) - need to submit an IRB to them. Dr. Hess is local contact\n\n-ACT (smaller version of PCORNET)\n\n-Clinithink\n\n-TriNetX\n\n-Epic Cosmos\n\nData Science Services (since \\~2016) - handles query with research.\n\n-   Services prioritized if they involve a grant or a grant application (4h, or requires seed function). Also can be prioritized as short queue (4-5 hours or less).\n\n-   \n\n    ```         \n      In the future, there will be a merit reward to prioritize your project. \n    ```\n\n## Formatting {#sec-formatting}\n\nStep 0: Save yourself a headache and collect your data in a processable format [https://open.substack.com/pub/statsepi/p/simple-tips-for-recording-data-in](https://open.substack.com/pub/statsepi/p/simple-tips-for-recording-data-in?utm_campaign=post&utm_medium=web) \n\nFormat article: <https://journals.plos.org/ploscompbiol/article?id=10.1371%2Fjournal.pcbi.1012604&utm_source=substack&utm_medium=email>\n\nnaming: <https://benharrap.com/post/2025-03-03-variable-naming-convention/>\n\nData abstraction: \n\nData from web tables  <https://twitter.com/asmith83/status/1549373680496656385?s=21&t=4SAl-DHtn3zREP_avr6XaA>\n\nData collection with excel - <https://www.youtube.com/watch?v=Ry2xjTBtNFE> Also <https://twitter.com/blakeaburge/status/1540666548616036353?s=11&t=Dl6FGUjENZiqAT0eXQ_I6A> \n\n**Step 1: Data Wrangling**\n\nnaming variables: <https://emilyriederer.netlify.app/post/column-name-contracts/> \n\n![](images/clipboard-1599530648.png)\n\n-   Each row is an observation (usually a patient)\n-   Each column contains only 1 type of data (more below)\n-   No free text (if you need to, categorize responses)\n\nClean tabular format etc.\n\nPresentation on Cleaning - <https://cghlewis.github.io/ncme-data-cleaning-workshop/slides.html>\n\nUse excel like a boss, if you're going to: More excel data https://cghlewis.com/blog/excel_entry/\n\nFlat files: Flat files: https://evidence.dev/blog/what-is-a-flat-file?utm_campaign=Data_Elixir&utm_source=Data_Elixir_526\n\n\\[ \\] data checklist - find attribution for this\n\n\\### \\*\\*Data Quality Indicator Checklist\\*\\*\n\n\\#### \\*\\*✓ Analyzable\\*\\*\n\n\\- Dataset is in a rectangular (rows and columns), machine-readable format. Variable names are the first row only. The remaining data should be made up of values in cells.\n\n\\- One or more columns uniquely identify rows in the data (i.e., primary key).\n\n\\- All column values are explicit.\n\n  - No values are indicated by color coding.\n\n  - All non-missing values are explicitly defined (e.g., if a blank is assumed to be 0, it is filled with a 0).\n\n\\- Only one piece of information is contained in a variable.\n\n\\#### \\*\\*✓ Complete\\*\\*\n\n\\- Everyone in your sample (e.g., consented, included in the study, completed the instrument) is accounted for.\n\n\\- If you collected it, it should exist in the file.\n\n\\- There should be no rows with duplicate primary keys (e.g., study unique identifiers).\n\n\\#### \\*\\*✓ Interpretable\\*\\*\n\n\\- Variable names are machine-readable (i.e., no special characters or spaces) AND human-readable (consistently formatted and clear to humans).\n\n\\- Variable and value labels are added if sharing in SPSS, Stata, or SAS format.\n\n  - Consider sharing in at least one non-proprietary format (e.g., CSV).\n\n\\#### \\*\\*✓ Valid\\*\\*\n\n\\- Variables conform to the constraints that you have laid out in your data dictionary.\n\n  - Planned variable types (e.g., numeric, character, date).\n\n  - Allowable variable values and ranges (e.g., 1-50).\n\n  - Item-level missingness aligns with variable universe and skip patterns.\n\n\\#### \\*\\*✓ Accurate\\*\\*\n\n\\- There are no glaring errors in the data that you have not acknowledged.\n\n  - Based on any implicit knowledge you have.\n\n  - Based on a comparison of information within and across sources.\n\n\\#### \\*\\*✓ Consistent\\*\\*\n\n\\- Variable values are consistently measured, formatted, or categorized within a column.\n\n\\- Variables are consistently measured across collections of the same form.\n\n\\#### \\*\\*✓ De-identified\\*\\*\n\n\\- Disclosure risks have been addressed (both direct and indirect identifiers have been removed/altered as needed).\n\n#### Document Codebooks:\n\n<https://cghlewis.com/talk/rladies_nyc/> comparison of ways to do this in R\n\n## Primer on Data types {#sec-data_types}\n\n**Step 2: For each data element, consider the data type**\n\n-   Binary (aka dichotomous scale): e.g. Yes or No, 0 or 1\n-   Unordered Categorical (nominal scale): e.g. Utah, Colorado, Nevada, Idaho\n-   Ordered Categorical (ordinal scale): e.g. Room air, nasal cannula, HFNC, intubated, ECMO, dead\n-   Continuous (interval & ratio scales - differ by whether 0 is special): e.g. Temperature (Celsius or Kelvin, respectively)\n\n|           |                 |             |                     |              |\n|-----------|-----------------|-------------|---------------------|--------------|\n|           | **dichotomous** | **nominal** | **ordinal**         | **interval** |\n| a.ka.     | binary          | categorical | ordered categorical | continuous   |\n| n         | X               | X           | X                   | X            |\n| \\%        | X               | X           | X                   | X            |\n| min       |                 |             | X                   | X            |\n| max       |                 |             | X                   | X            |\n| range     |                 |             | X                   | X            |\n| mode      | X               | X           | X                   | X            |\n| mean      |                 |             |                     | X            |\n| median    |                 |             | X                   | X            |\n| IQR       |                 |             | X                   | X            |\n| Std. dev. |                 |             |                     | X            |\n| Std. err. |                 |             |                     | X            |\n\nFrom: Stoddard GJ. Biostatistics and Epidemiology Using Stata: A Course Manual. Salt Lake City, UT: University of Utah School of Medicine.\n\nTODO: not sure this stuff should live here vs elsewhere:\n\n**Step 3: Visualize the distribution of each data-point** (detect outliers, data entry errors, etc.)\n\nDarren's hypothetical code lives in a spreadsheet \"darren_proj.xlsx\":\n\nHere is some code that loads the excel spreadsheet into R (we'll revisit)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n:::\n\n\nIt's already (mostly) clean.\n\nLet's summarize it:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(darren_data_sheet)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   patient_id    splenectomy        prox_v_dist           qanadli     \n Min.   : 1.00   Length:20          Length:20          Min.   : 2.00  \n 1st Qu.: 5.75   Class :character   Class :character   1st Qu.: 3.75  \n Median :10.50   Mode  :character   Mode  :character   Median :10.00  \n Mean   :10.50                                         Mean   :10.30  \n 3rd Qu.:15.25                                         3rd Qu.:15.00  \n Max.   :20.00                                         Max.   :25.00  \n   got_cteph?       hosp          \n Min.   :0.00   Length:20         \n 1st Qu.:0.00   Class :character  \n Median :0.00   Mode  :character  \n Mean   :0.25                     \n 3rd Qu.:0.25                     \n Max.   :1.00                     \n```\n\n\n:::\n:::\n\n\nHmmm.. what's wrong with this?\n\nR need to be told that the binary variables are binary (and not characters)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\n# Convert 'y'/'n' in the splenectomy column to TRUE/FALSE\ndarren_data_sheet <- darren_data_sheet %>%\n  mutate(splenectomy = ifelse(splenectomy == \"y\", TRUE, FALSE))\n\n# Assuming darren_data_sheet is your dataframe\ndarren_data_sheet <- darren_data_sheet %>%\n  mutate(`got_cteph?` = ifelse(`got_cteph?` == 1, TRUE, FALSE))\n```\n:::\n\n\nLet's visualize each element:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\n# First, the binary ones\n\n# Plot for splenectomy\nggplot(darren_data_sheet, aes(x = factor(splenectomy))) +\n  geom_bar() +\n  labs(title = \"Distribution of Splenectomy\", x = \"Splenectomy\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](data_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n# Plot for prox_v_dist\nggplot(darren_data_sheet, aes(x = factor(prox_v_dist))) +\n  geom_bar() +\n  labs(title = \"Distribution of Proximal vs. Distal\", x = \"Proximal vs Distal\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](data_files/figure-html/unnamed-chunk-5-2.png){fig-align='center' width=100%}\n:::\n\n```{.r .cell-code}\n# Plot for got_cteph?\nggplot(darren_data_sheet, aes(x = factor(`got_cteph?`))) +\n  geom_bar() +\n  labs(title = \"Distribution of CTEPH Diagnosis\", x = \"Got CTEPH?\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](data_files/figure-html/unnamed-chunk-5-3.png){fig-align='center' width=100%}\n:::\n:::\n\n\nThe categorical one:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Bar chart for hosp\nggplot(darren_data_sheet, aes(x = factor(hosp))) +\n  geom_bar(fill = \"coral\", color = \"black\") +\n  labs(title = \"Distribution of Hospital\", x = \"Hospital\", y = \"Count\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Adjust text angle for better readability if needed\n```\n\n::: {.cell-output-display}\n![](data_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\nand finally, the continuous one:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Histogram for qanadli\nggplot(darren_data_sheet, aes(x = qanadli)) +\n  geom_histogram(bins = 30, fill = \"blue\", color = \"black\") +\n  labs(title = \"Histogram of Qanadli Scores\", x = \"Qanadli Score\", y = \"Frequency\")\n```\n\n::: {.cell-output-display}\n![](data_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Exploratory Data analysis:\n\nPackages to expedite:\\\nR - <https://cosimameyer.com/post/exploratory-data-analysis-in-r/?utm_source=substack&utm_medium=email>\n\nPython - <https://cosimameyer.com/post/exploratory-data-analysis-in-python/?utm_source=substack&utm_medium=email>\n\n## Additional references:\n\n<https://johnborghi.github.io/Supporting_Scientific_Data/>\n\nYoutube video from Dahly - <https://www.youtube.com/watch?v=Ry2xjTBtNFE&t=145s&utm_source=substack&utm_medium=email>\n\nData cleaning resources: <https://www.anyamemensah.com/blog/recoding-cols-python?utm_source=substack&utm_medium=email>\n",
    "supporting": [
      "data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}